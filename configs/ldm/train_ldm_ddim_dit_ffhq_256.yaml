_import: configs/train_base_gt_data.yaml

boat:

  path: 'rhdiffusion.boats.latent_diffusion_boat'
  name: 'LatentDiffusionBoat'

  models: 
    net:
      path: 'rhdiffusion.nn.model_zoo.dit.dit'
      name: 'DiT'
      params:
        img_size: $img_size
        patch_size: $patch_size
        in_channels: $in_channels
        hidden_size: $hidden_size

    # net:
    #   path: 'diffusers.models.unets'
    #   name: 'UNet2DModel'
    #   config:
    #     in_channels: $in_channels
    #     out_channels: $in_channels
    #     sample_size: $img_size
    #     down_block_types: ['DownBlock2D', 'DownBlock2D', 'DownBlock2D', 'AttnDownBlock2D']
    #     up_block_types: ['AttnUpBlock2D', 'UpBlock2D', 'UpBlock2D', 'UpBlock2D']
    #     block_out_channels: [64, 128, 256, 256]
    #     layers_per_block: 1
    #     attention_head_dim: 8
    #     norm_num_groups: 32
    #     norm_eps: 0.00001

    # latent_encoder:
    #   path: 'rhcompression.nn.wrappers.autoencoder_kl_wrapper'
    #   name: 'AutoencoderKLWrapper'
    #   pretrained: 'stabilityai/sd-vae-ft-mse'

    latent_encoder:
      path: 'rhcompression.nn.model_zoo.autoencoder_kl'
      name: 'AutoencoderKL'
      params:
        ddconfig:
          double_z: True
          z_channels: 4
          resolution: 256
          in_channels: 3
          out_ch: 3
          ch: 128
          ch_mult: [1, 2, 4, 4]    # num_down = len(ch_mult) - 1  → 3 downsamples ⇒ 8× downsampling
          num_res_blocks: 2
          attn_resolutions: []      # no self-attn in the VAE
          dropout: 0.0
        embed_dim: 4
        load_pretrained: 'pretrained/sdvae_ffhq_256_pretrained_models/net_ema_pretrained.pt'

    scheduler:
      path: 'rhdiffusion.schedulers.scheduling_ddim'
      name: 'DDIMScheduler'
      config:
        beta_start: 0.0001
        beta_end: 0.02
        beta_schedule: "linear"
        steps_offset: 1
        clip_sample: false
        set_alpha_to_one: false
        prediction_type: "epsilon"
        num_train_timesteps: 1000

    solver:
      path: 'rhdiffusion.solvers.sampling_ddim'
      name: 'DDIMSampler'         # Name of the model class to use
      config:
        beta_start: 0.0001
        beta_end: 0.02
        beta_schedule: "linear"
        steps_offset: 1
        clip_sample: false
        set_alpha_to_one: false
        prediction_type: "epsilon"
        num_train_timesteps: 1000
        eta: 0.0                   # Parameter controlling noise level in sampling
        num_inference_steps: 50    # Default sampling steps for inference

  losses: 
    net:
      path: 'rhopsr.nn.losses.weighted_loss'
      name: 'WeightedLoss'
      params:
        base_loss_fn_str: mse
      wrapper: # This wrapper is more complex needs parameters
        mpath: 'rhopsr.nn.losses.wrappers.list_of_keys.ListOfKeys'
        params:
          keys: ["preds", "targets", "weights"]

optimization: 
  net:
    path: 'torch.optim'
    name: 'Adam'
    params:
      lr: 0.0001
      betas: [0.9, 0.999]
      weight_decay: 0.0
    lr_scheduler: {}
    
  use_ema:
    ema_decay: 0.999
    ema_start: $ema_start

trainer:
  devices: $devices
  max_epochs: $max_epochs
  val_check_epochs: 1
  state_save_epochs: 1

visualization:
  save_images: true
  first_batch_only: true
  wnb: [0.5, 0.5]  # for visualization
  num_vis_samples: 4

validation: 
  target_metric_name: 'dummy_metric'
  metrics:
    dummy_metric:
      path: 'rhino.metrics.dummy_metric'
      name: 'DummyMetric'
      params: {}
      wrapper: 'rhcore.metrics.wrappers.dict_2_params.Dict2ListParams'

logging:
  root_dir: 'work_dirs'
  name: $experiment_name
  loggers:
    tensorboard:
      path: 'trainer.loggers.tensorboard'
      name: 'TensorBoardLogger'
      params:
        log_dir: 'work_dirs'
        name: $experiment_name

callbacks: 
  - path: trainer.callbacks.state_cleaner
    name: KeepTopKStateCallback
    params:
      top_k: 5

_vars:

  devices: [1]
  max_epochs: 200

  train_batch_size: 128
  valid_batch_size: 16
  num_workers: 16

  img_size: 32
  patch_size: 2
  in_channels: 4
  hidden_size: 512

  train_folder_paths:
    gt: data/ffhq/ffhq_imgs/ffhq_256
    
  valid_folder_paths:
    gt: data/celeba/subsets/celeba_256

  experiment_name: ldm_ddim_dit_ffhq_256

  ema_start: 0