_import: configs/train_base_config.yaml

boat:
  path: 'rhdiffusion.boats.latent_diffusion_boat'
  name: 'LatentDiffusionBoat'
  
  pretrained:
    latent_encoder:
      path: 'rhdiffusion.nn.wrappers.autoencoder_kl_wrapper'
      name: 'AutoencoderKLWrapper'
      pretrained: 'stabilityai/sd-vae-ft-mse'

  models: 
    net:
      path: 'diffusers.models.unets'
      name: 'UNet2DModel'
      config:
        in_channels: $in_channels
        out_channels: $out_channels
        sample_size: $sample_size
        down_block_types: ['DownBlock2D', 'DownBlock2D', 'DownBlock2D', 'AttnDownBlock2D']
        up_block_types: ['AttnUpBlock2D', 'UpBlock2D', 'UpBlock2D', 'UpBlock2D']
        block_out_channels: [32, 64, 128, 128]
        layers_per_block: 1
        attention_head_dim: 8
        norm_num_groups: 16
        norm_eps: 0.00001

  losses: 
    net:
      path: 'rhopsr.nn.losses.weighted_loss'
      name: 'WeightedLoss'
      params:
        base_loss_fn_str: mse
      wrapper: # This wrapper is more complex needs parameters
        mpath: 'rhopsr.nn.losses.wrappers.list_of_keys.ListOfKeys'
        params:
          keys: ["prediction", "target", "weight"]

  samplers:
    net:
      path: 'rhdiffusion.samplers.ddim_sampler'
      name: 'DDIMSampler'         # Name of the model class to use
      config:
        beta_start: 0.0001
        beta_end: 0.02
        beta_schedule: "linear"
        steps_offset: 1
        clip_sample: false
        set_alpha_to_one: false
        prediction_type: "epsilon"
        num_train_timesteps: 1000
        eta: 0.0                   # Parameter controlling noise level in sampling
        num_inference_steps: 50    # Default sampling steps for inference

_vars:

  devices: [0, 1]
  max_epochs: 500

  train_batch_size: 128
  valid_batch_size: 16
  num_workers: 16

  in_channels: 4
  out_channels: 4
  sample_size: [32, 32]

  train_folder_paths:
    gt: data/ffhq/ffhq_imgs/ffhq_256
    
  valid_folder_paths:
    gt: data/celeba/subsets/celeba_256

  experiment_name: ldm_unet_ffhq_256

  ema_start: 0