_import: configs/train_base_ddim.yaml

boat:
  path: 'rhdiffusion.boats.latent_diffusion_boat'
  name: 'LatentDiffusionBoat'
  
  models:
    latent_encoder:
      path: 'rhcompression.nn.wrappers.autoencoder_kl_wrapper'
      name: 'AutoencoderKLWrapper'
      pretrained: 'stabilityai/sd-vae-ft-mse'

_vars:

  net:
    path: 'diffusers.models.unets'
    name: 'UNet2DModel'
    config:
      in_channels: $in_channels
      out_channels: $out_channels
      sample_size: $sample_size
      down_block_types: ['DownBlock2D', 'DownBlock2D', 'DownBlock2D', 'AttnDownBlock2D']
      up_block_types: ['AttnUpBlock2D', 'UpBlock2D', 'UpBlock2D', 'UpBlock2D']
      block_out_channels: [64, 128, 256, 256]
      layers_per_block: 1
      attention_head_dim: 8
      norm_num_groups: 32
      norm_eps: 0.00001

  devices: [0, 1, 2, 3]
  max_epochs: 200

  train_batch_size: 32
  valid_batch_size: 16
  num_workers: 16

  in_channels: 4
  out_channels: 4
  sample_size: [32, 32]

  train_folder_paths:
    gt: data/ffhq/ffhq_imgs/ffhq_256
    
  valid_folder_paths:
    gt: data/celeba/subsets/celeba_256

  experiment_name: ldm_unet_ffhq_256

  ema_start: 0